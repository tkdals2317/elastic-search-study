## 4.2 복수 문서 API

- 엘라스틱서치의 API는 기본적으로 HTTP를 이용하는 REST API다.
- 단건 API로 많은 처리를 할 시 오버헤드가 매우 크므로 실제 서비스 환경에서는 최대한 단건 문서 API보다는 복수 문서 API를 활용해야 한다.
- 이번 절에서는 여러 문서를 색인, 업데이트, 삭제할 때 사용하는 bulk API에 대해 알아본다.
- 그리고 여러 문서를 한 번에 조회할 때 사용하는 multi get API를 알아본다.
- 특정한 조건을 만족하는 문서를 대상으로 작업하는 update by query와 delete by query API에 대해 알아본다.

### 4.2.1 bulk API

- bulk API는 여러 색인, 업데이트, 삭제 작업을 한 번에 요청에 담아서 보내는 API다.
- 실제 서비스에서 특히 대량의 데이터를 색인할 때 많이 사용된다.
- 요청 본문을 JSON이 아닌 NDJSON 형태로 만들어서 보낸다.
- Content-Type 헤더도 application/json 대신 application/x-ndjson을 사용해야 한다.
- 가장 마지막 줄도 줄바꿈 문자 \n으로 끝나야 한다.

```
POST _bulk
{"index":{"_index":"bulk_test", "_id":"1"}}
{"field1":"value1"}
{"delete":{"_index":"bulk_test", "_id":"2"}}
{"create":{"_index":"bulk_test", "_id":"3"}}
{"field1":"value3"}
{"update":{"_id":"1","_index":"bulk_test"}}
{"doc":{"field2":"value2"}}
{"index":{"_index":"bulk_test","_id":"4", "routing":"a"}}
{"field1":"value4"}
```

위 요청은 5개의 세부 요청으로 이뤄져 있다.

1. 첫 줄은 요청의 종류와 인덱스, _id, 라우팅 등을 지정한다.

   ex) `{"index":{"_index":"bulk_test", "_id":"1"}}`

2. 해당 요청이 만약 추가적인 요청 본문을 필요로 하는 경우 다음 줄에 이어서 기재한다. 예를 들어 색인 요청이라면 색인할 문서 내용이 필요한데 그 다음 줄에 쓰면 된다.

   ex) `{"field1":"value1"}`


따라서 요청 하나의 크기는 1줄 또는 2줄이 된다.

위 예는 다음과 같이 끊어서 파악할 수 있다.

```
{"index":{"_index":"bulk_test", "_id":"1"}}
{"field1":"value1"}
```

⇒ bulk_test라는 인덱스에 _id는 1로 {"field1":"value1"} 문서를 index로 색인 요청

⇒ index는 기존에 동일한 _id로 문서가 존재하는지 여부와 상관없이 항상 색인 작업을 수행한다.

```
{"delete":{"_index":"bulk_test", "_id":"2"}}
```

⇒ bulk_test라는 인덱스에 _id는 2에 해당하는 문서 삭제

```
{"create":{"_index":"bulk_test", "_id":"3"}}
{"field1":"value3"}
```

⇒ bulk_test라는 인덱스에 _id는 3로 {"field1":"value3"} 문서를 create로 색인 요청

⇒ create는 새 문서를 생성하는 것만 허용하고 기존 문서를 덮어쓰지 않고 색인 요청

```
{"update":{"_id":"1","_index":"bulk_test"}}
{"doc":{"field2":"value2"}}
```

⇒ bulk_test라는 인덱스에 _id가 1에 해당하는 문서를 업데이트 한다.

⇒ 두 번째 줄에 doc 또는 script를 기술하여 업데이트를 수행한다.

```
{"index":{"_index":"bulk_test","_id":"4", "routing":"a"}}
{"field1":"value4"}
```

⇒ bulk_test라는 인덱스에 _id는 4로 {"field1":"value4"} 문서를 라우팅을 “a”로 지정하여 색인

```
POST [인덱스 이름]/_bulk
```

만약 _bulk 앞에 인덱스 이름을 넣으면 요청의 기본 대상이 해당 인덱스로 지정된다.

bulk API 내의 세부 요청 중 _index를 지정하지 않은 요청은 이 기본 인덱스를 지정한 요청이 된다.

bulkAPI의 응답은 각 세부 요청을 수행하고 난 결과를 모아 하나의 응답으로 돌아온다.

```
{
  "took": 419,
  "errors": false,
  "items": [
    {
      "index": {
        "_index": "bulk_test",
        "_id": "1",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 1,
          "failed": 0
        },
        "_seq_no": 0,
        "_primary_term": 1,
        "status": 201
      }
    },
    {
      "delete": {
        "_index": "bulk_test",
        "_id": "2",
        "_version": 1,
        "result": "not_found",
        "_shards": {
          "total": 2,
          "successful": 1,
          "failed": 0
        },
        "_seq_no": 1,
        "_primary_term": 1,
        **"status": 404 <= 존재하지 않은 문서를 삭제하려고 시도하여 404로 응답**
      }
    },
    {
      "create": {
        "_index": "bulk_test",
        "_id": "3",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 1,
          "failed": 0
        },
        "_seq_no": 2,
        "_primary_term": 1,
        "status": 201
      }
    },
    {
      "update": {
        "_index": "bulk_test",
        "_id": "1",
        "_version": 2,
        "result": "updated",
        "_shards": {
          "total": 2,
          "successful": 1,
          "failed": 0
        },
        "_seq_no": 3,
        "_primary_term": 1,
        "status": 200
      }
    },
    {
      "index": {
        "_index": "bulk_test",
        "_id": "4",
        "_version": 1,
        "result": "created",
        "_shards": {
          "total": 2,
          "successful": 1,
          "failed": 0
        },
        "_seq_no": 4,
        "_primary_term": 1,
        "status": 201
      }
    }
  ]
}
```

전체 응답의 상태코드는 200으로 클라이언트는 200을 받았다고 안심하지 말고 세부 응답을 파싱해서 원하는 대로 작업이 수행됬는 지 확인해야한다.

> **bulk API의 작업 순서**
>

bulk API에 기술된 작업은 반드시 그 **순서대로 수행된다는 보장이 없다.**

그 이유는 다음의 순서로 진행되기 때문이다.

1. 조정 역할을 하는 노드가 요청을 수신하면 각 요청의 내용을 보고 적절한 주 샤드로 요청을 넘겨준다.
2. 여러 개의 주 샤드에 넘어간 각 요청은 각자 독자적으로 수행된다.

따라서 요청 간 순서는 보장되지 않는다.

그러나 완전히 동일한 인덱스, _id, 라우팅 조합을 가진 요청은 반드시 동일한 주샤드로 넘어가므로, bulk API에 기술된 순서대로 동작한다.

> **bulk API의 성능**
>

네트워크를 통해 요청을 여러 번 반복해서 호출해야 한다면 이를 묶어 한꺼번에 전송하는 것이 일반적으로 성능상 이득이다.

각 요청의 크기나 데이터 특성이 다 다르기에 bulk API 요청 한 번에 몇 개의 요청을 모아서 보내는 것이 성능상 적절한지는 정해져 있지는 않다.

⇒ 성능 이슈가 있는 경우 적절치를 조절해 가며 실험해 보는 것이 좋다.

⇒ HTTP 요청을 청크로 보내는 것은 성능을 떨어지게 만들기 때문에 피해야 한다.

### 4.2.2 multi get API

multi get API는 _id를 여럿 지정하여 해당 문서를 한 번에 조회하는 API다.

단건 조회 API를 반복해서 사용하는 것보다 성능이 좋다.

```
GET _mget
GET [인덱스 이름]/_mget
```

요청 본문에는 docs 필드 밑에 각 세부 조회 요청을 기술한다.

각 세부 요청은 _index, _id를 포함해야 하며 라우팅이나 특정 필드 포함 및 제거 옵션들을 함께 기술할 수 있다.

```
GET _mget
{
  "docs":[
    {
      "_index": "bulk_test",
      "_id": 1
    },
    {
      "_index": "bulk_test",
      "_id": 4,
      "routing": "a"
    },
    {
      "_index": "my_index2",
      "_id": "1",
      "_source":{
        "include":["p*"],
        "exclude":["point"]
      }
    }
  ]
}
```

```
{
  "docs": [
    {
      "_index": "bulk_test",
      "_id": "1",
      "_version": 2,
      "_seq_no": 3,
      "_primary_term": 1,
      "found": true,
      "_source": {
        "field1": "value1",
        "field2": "value2"
      }
    },
    {
      "_index": "bulk_test",
      "_id": "4",
      "_version": 1,
      "_seq_no": 4,
      "_primary_term": 1,
      "_routing": "a",
      "found": true,
      "_source": {
        "field1": "value4"
      }
    },
    {
      "_index": "my_index2",
      "_id": "1",
      "_version": 1,
      "_seq_no": 0,
      "_primary_term": 1,
      "found": true,
      "_source": {
        "public": true
      }
    }
  ]
}
```

응답은 위와 같이 요청했던 순서대로 문서의 내용을 모아 단일 응답으로 돌아온다.

_mget 앞에 인덱스 이름을 명시했다면 bulk API와 마찬가지로 이 인덱스가 기본으로 지정된다.

요청 본문에서 _index를 생략할 수 있다. 그런 경우 요청 본문에 docs가 아니라 ids만 기술해서 요청할 수 있다.

```
GET bulk_test/_mget
{
  "ids":["1", "3"]
}
```

### 4.2.3 update by query

검색 쿼리를 통해 주어진 **조건을 만족하는 문서**를 찾은 뒤 **그 문서를 대상으로 업데이트 하는 API**이다.

동작상 서비스에 일상적으로 사용하기보다는 **관리적인 목적으로 호출**할 때가 많다.

```
POST [인덱스 이름]/_update_by_query
{
	"script": {
		"source": " // ...",
	},
	"query": {
		//...
	}
}
```

**update by query API**는 단건 업데이트 API와 달리 **doc을 이용한 업데이트를 지원하지 않는다.**

script를 통한 업데이트만을 지원한다.

또한 업데이트 API에서 사용 가능한 painless 스크립트 문맥 정보 중에서 ctx._now를 사용할 수 없다.

**update by query API 동작 순서**

1. 엘라스틱서치는 query 절의 검색 조건에 맞는 문서를 찾아 일종의 스냅샷을 찍는다.
2. 이후 각 문서마다 지정된 스크립트에 맞게 업데이트를 실시한다.

**문서 변경으로 인한 충돌 처리 방법**

여러 문서의 업데이트가 순차적으로 진행되는 도중 문서의 변경이 생길 수 있다.

스냅샷을 찍어 뒀던 문서에서 **변화가 생긴 문서를 발견하면 이를 업데이트 하지 않는다.**

버전 충돌 문제가 생기면 전체 작업을 해당 지점에서 그만둘 수도 있고 다음 작업으로 넘어갈 수도 있다.

conflict 매개변수를 지정하면 이때 동작 방식을 지정할 수 있다.

- abort : 충돌 발견 시 작업을 중단한다.
- proceed : 다음 작업으로 넘어간다(default 값)

**실습**

문서의 `field1` 이름을 가진 필드가 존재하는 문서를 찾아 `field1-[ctx._id]` 로 업데이트 한다.

```
POST bulk_test/_update_by_query
{
  "script": {
    "source": "ctx._source.field1 = ctx._source.field1 + '-' + ctx._id",
    "lang": "painless"
  },
  "query": {
    "exists": {
      "field": "field11"
    }
  }
}
```

```
{
  "took": 102, // 쿼리 실행에 걸린 시간(밀리초)
  "timed_out": false, // 쿼리 실행 시 타임ㅇ아웃 발생 여부
  "total": 3, // 업데이트 된 대상의 문서의 총 개수
  "updated": 3, // 업데이트 된 문서의 개수
  "deleted": 0, // 삭제된 문서의 수
  "batches": 1, //처리된 배치의 수 대량의 데이터를 처리할 때 여러 배치로 나누어 처리하게 된다.
  "version_conflicts": 0, // 문서를 업데이트 중 버전 충돌의 수
  "noops": 0, // 아무 작업도 수행되지 않은 문서의 수
  "retries": { // 재시도 횟수
    "bulk": 0, // 대량 작업에서의 재시도 횟수
    "search": 0 // 검색 작업에서의 재시도 횟수
  },
  "throttled_millis": 0, // 요청이 스로틀링되어 대기한 시간(스로틀링이란 시스템 과부하를 막기위해 일부러 요청 처리속도를 늦추는 것을 말함)
  "requests_per_second": -1, // 초당 요청 수 -1은 속도 제한이 없음을 의미
  "throttled_until_millis": 0, // 다음 요청이 스로틀링 없이 처리될 때까지 대기해야 되는 시간
  "failures": [] // 실해 목록
}
```

```
GET bulk_test/_search
{
  "query": {
    "exists": {
      "field": "field"
    }
  }
}
```

> **스로틀링**
>

대량 작업을 수행하다보면 운영 중인 기존 서비스에 양향을 줄 수 있다.

그러한 상황을 피하기 위해 update by query에는 스로틀링 기능이 있다.

적절한 스로틀링 적용을 통해 **작업 속도를 조정**하고 **클러스터 부하와 서비스 영향을 최소화**할 수 있다.

```
POST bulk_test/_update_by_query?**scroll_size=1000&scroll=1m&requests_per_second=500**
{
	// ...
}
```

- **scroll_size**
    - 스로틀링의 단위를 조정하는 설정이다.
    - 기본 값으로는 한 번의 검색 수행에 1000개의 문서를 가져 온 뒤 1000개의 문서에 대한 업데이트를 수행한다.
    - 페이징 사이즈라고 보면 될 거 같다.
- **scroll**
    - 검색 조건을 만족한 모든 문서를 대상으로 검색이 처음 수행됐을 당시 상태를 검색 문맥(search context)에 보존하게 되는데 이 검색 문맥을 얼마나 보존할 지 지정하는 설정
    - 위 예제에서는 1분 동안 검색 문맥이 유지된다.
    - 모든 작업이 종룓될 때 까지 필요한 시간을 지정하는 것이 아니라 한 배치 작업에 필요한 시간을 지정하면 된다.
    - scroll_size만큼의 작업 처리가 가능해야 하므로 너무 짧은 값을 지정하면 안된다.
    - 힙 메모리와 디스크 공간, 파일 기술자(file descriptor)를 차지하므로 스크롤이 과다하게 열려 있지 않도록 너무 큰 값을 지정하지 않아야 한다.
- **requests_per_second** :
    - 스로틀링을 실제 적용 시 평균적으로 초당 몇 개까지의 작업을 수행할 것인지를 지정한다.
    - 실제 동작은 scoll_size 단위로 업데이트 작업을 수행한 뒤 이 값에 맞도록 일정 시간을 대기하는 방식으로 진행된다.
    - scoll_size를 1000으로 설정하고 requests_per_second를 500으로 설정 시 2초마다 스크롤 한번 분량 만큼 업데이트를 한다.
    - 스크롤 한 번 분량만큼 업데이트 작업한 시간이 0.5초라면 1000개 업데이트에 0.5초를 사용한 뒤 1.5초를 대기하고  다시 다음 1000개 업데이트를 수행하는 방식으로 평균 초당 500개 업데이트라는 수치를 맞춘다.
    - requests_per_second과 scoll_size 값을 조절하는 것이 스로틀링 조정의 핵심이다.
    - requests_per_second의 기본 값은 -1로 스로틀링을 적용하지 않는 설정이다.

스로틀링 적용해서 수행한 update by query의 응답은 다음과 같은 형태다.

```
  {
	  // ...
	  "throttled_millis": 2999, // 작업을 진행하지 않고 대기한 총 시간
	  "requests_per_second": 500,
	  // ...
  }
```

> **비동기적 요청과 tasks API**
>

실제 대형 서비스를 운영하는 중 대량의 update by query 작업을 수행해야 한다면 대부분은 스로틀링을 적용해서 시간을 넉넉히 작아 클러스터의 부담과 서비스 리스크를 줄이고 안전하게 작업을 수행했을 것이다.

그렇다면 전체 작업이 종료되는 시간은 수십 시간이 될수도 있다.

HTTP 요청 결과의 응답을 확인하기 위해 수십 시간을 대기해야 했다면 대부분의 HTTP 클라이언트는 이미 타임아웃을 냈을 것이다. 만약 작업 도중 문제가 발생했더라도 응답에서 이를 확인하기 어려워진다.

**⇒ 비동기적인 요청 tasks API로 해결 가능하다.**

wait_for_completion 매개변수를 false로 지정하면 비동기적 처리를 할 수 있다.

해당 요청을 받으면 엘라스틱 서치는 작업을 task로 등록한 뒤 즉시 task의 id가 포함된 응답을 반환한다.

이 값은 노드의 id와 해당 노드 내 task내의 id를 콜론(:)으로 연결한 형태다.

이 값으로 tasks API를 호출함으로써 작업의 진행률과 진행 결과를 확인하거나 작업 취소를 할 수있다.

**task 작업 등록과 상태 조회**

update by query는 wait_for_completion 값에 상관없이 모두 task의 형태로 동작하며 tasks 조회 API를 통해 작업 진행을 확인할 수 있다. (비동기와 여부와 상관없이 task로 동작한다.)

다만 wait_for_completion 값을 **false로 지정**하면 이 **진행 상황이 .task라는 내부 인덱스에 문서로 저장된다.**

또한 **작업이 종료된 이후에도 작업 결과를 조회할 수 있다.**

**실습**

```
POST [인덱스 이름]/_update_by_query?**wait_for_completion=false**
```

```
{
	"task" : "ph93zSQORi6vPBV7SlE8Rw:1202337" // [노드 id] : [task내의 id] 형태
}
```

이제 이 값을 가지고 task의 상태를 확인해보자

```
GET .task/_doc/[task_id]
GET _task/[task_id]
```

`GET .task/_doc/[task_id]` : 내부 인덱스인 .tasks의 문서를 문서 조회 API로 조회하여 확인

`GET _task/[task_id]` : tasks 관리 API 중 조회 API를 호출

tasks 관리 API(_tasks)에서는 .tasks 인덱스에 등록되지 않은 작업도 확인할 수 있다.

다음은 tasks API를 호출해서 tasks로 등록한 update by query의 상태를 확인한 결과다.

```
GET _tasks/ph93zSQORi6vPBV7SlE8Rw:1202337
```

```
{
  **"completed": true**, // 작업의 완료 여부(false일 시 진행중)
  "task": {
    "node": "ph93zSQORi6vPBV7SlE8Rw", // 작업이 실행된 노드의 고유 식별자
    "id": 1202337, // 작업의 고유 식별자
    "type": "transport", // 작업 유형
    "action": "indices:data/write/update/byquery", // 수행된 작업의 구체적인 액션
    "status": {
      "total": 0,
      "updated": 0,
      "created": 0,
      "deleted": 0,
      "batches": 0,
      "version_conflicts": 0,
      "noops": 0,
      "retries": {
        "bulk": 0,
        "search": 0
      },
      "throttled_millis": 0,
      "requests_per_second": -1,
      "throttled_until_millis": 0
    },
    "description": "update-by-query [bulk_test] updated with Script{type=inline, lang='painless', idOrCode='ctx._source.field1 = ctx._source.field1 + '-' + ctx._id', options={}, params={}}",
    "start_time_in_millis": 1710172125747,
    "running_time_in_nanos": 1654000,
    "cancellable": true,
    "cancelled": false,
    "headers": {
      "trace.id": "1d7baa8df13097bd1703295eb69fb04c"
    }
  },
  "response": {
    "took": 0,
    "timed_out": false,
    "total": 0,
    "updated": 0,
    "created": 0,
    "deleted": 0,
    "batches": 0,
    "version_conflicts": 0,
    "noops": 0,
    "retries": {
      "bulk": 0,
      "search": 0
    },
    "throttled": "0s",
    "throttled_millis": 0,
    "requests_per_second": -1,
    "throttled_until": "0s",
    "throttled_until_millis": 0,
    "failures": []
  }
}
```

위 예는 작업이 완전히 종료됐을 때 볼 수 있는 응답이다. 작업이 진행 중이라면 completed 값이 false로 나오고 response 필드가 존재하지 않는다.

- 개인적인 궁금증으로 ChatGPT에 물어본 text와 action 필드 정보

  `**type` 필드**

  `type` 필드는 작업이 속한 범주 또는 유형을 나타냅니다. Elasticsearch에서는 다양한 유형의 작업을 처리할 수 있으며, 이 필드를 통해 해당 작업이 어떤 유형에 속하는지 식별할 수 있습니다.

  예를 들어, `"transport"` 유형은 네트워크를 통해 다른 노드로 전송되는 작업을 의미합니다.

  이는 Elasticsearch 클러스터 내에서 노드 간에 데이터를 이동하거나 명령을 전달할 때 사용되는 내부 메커니즘과 관련이 있습니다.

  다른 유형으로는 클러스터 관리, 인덱싱, 검색 등이 있을 수 있으며, 각각의 작업 유형은 Elasticsearch 내부에서 다른 방식으로 처리됩니다.

    - Transport: 클러스터 내의 노드 간 통신을 처리하는 작업 유형입니다. 데이터 전송, 요청 전달 등이 이에 속합니다.
    - Index: 데이터의 인덱싱 작업과 관련된 유형입니다. 문서 추가, 수정, 삭제 등이 포함될 수 있습니다.
    - Search: 데이터 검색과 관련된 작업 유형입니다. 쿼리 실행, 결과 반환 등의 작업이 여기에 속합니다.
    - Get: 특정 문서나 데이터를 검색하거나 가져오는 작업과 관련된 유형입니다.
    - Management: 클러스터나 인덱스 관리와 관련된 작업 유형입니다. 인덱스 생성, 삭제, 설정 변경 등이 포함됩니다.
    - Bulk: 대량의 데이터 처리와 관련된 작업 유형입니다. 대량의 문서 추가, 수정, 삭제 등이 여기에 속할 수 있습니다.
    - Snapshot: 클러스터나 인덱스의 스냅샷 생성, 복구와 관련된 작업 유형입니다.
    - Monitoring: 클러스터의 상태 모니터링, 로깅, 통계 수집과 관련된 작업 유형입니다.
    - Security: 보안과 관련된 작업 유형입니다. 사용자 인증, 권한 관리, 암호화 등이 포함됩니다.
    - Analysis: 데이터 분석과 관련된 작업 유형입니다. 텍스트 분석, 집계 작업 등이 여기에 속할 수 있습니다.

  `**action` 필드**

  `action` 필드는 수행된 구체적인 작업의 액션을 나타냅니다. 이 필드는 작업의 성격을 더욱 상세하게 설명하며, 어떤 작업이 실행되었는지에 대한 정보를 제공합니다. 예를 들어, `"indices:data/write/update/byquery"`는 인덱스 내의 데이터를 쿼리를 통해 업데이트하는 작업을 의미합니다.

    - `indices`: 인덱스 관련 작업을 나타냅니다.
    - `data/write`: 데이터 쓰기 작업을 나타냅니다.
    - `update`: 업데이트 작업을 나타냅니다.
    - `byquery`: 쿼리를 통한 업데이트임을 나타냅니다.


**task 작업 취소**

작업 진행 중 문제가 발생했다면 다음과 같이 작업을 취소한다.

```
POST _tasks/[task_id]/_cancel
```

응답은 실제로 캔슬을 하지 못해 설명으로 대체한다.

어떤 노드에서 작업이 취소됐는지, 그 노드의 어떤 task 작업이 취소됐는 지 확인할 수 있다.

취소에 실패했다면 응답에 node_failures 필드가 추가된다.

이 필드에서 어떤 사유로 작업 취소에 실패했는지 파악할 수 있다.

취소된 task를 tasks API로 다시 조회하면 status와 responce 필드 하위에 canceled 필드가 추가 된다.

.tasks 인덱스에 등록된 task만 취소할 수 있는 것은 아니다.

wait_for_completion=true로 지정해 호출한 작업이더라도 `GET _tasks` 를 호출하면 task 목록에서 진행 중인 작업을 확인할 수 있고 task id를 알아낸 후 취소를 요청할 수 있다.

**스로틀링 동적 변경**

진행 중인 task의 스로틀링을 동적으로 변경하여 update by query 실행 중 트래픽 급증과 같은 문제를 작업을 취소하지 않고 해결할 수있다.

```
POST _update_by_query[task_id]/**_rethrottle?request_per_second=[변경할 값]**
```

`_rethrottle` 옵션을 통해 스로틀링을 동적으로 변경하여 문제 상황에 유연하게 대처가 가능하다.

**tasks 결과 삭제**

`wait_for_completion=false` 를 통해 .tasks 인덱스에 등록된 작업이 성공하거나 쉬소됐는지 여부와 상관없이 등록된 작업 결과는 엘라스틱서치에 계속 남는다. 작업의 상황을 충분히 확인했다면 다음과 같이 .tasks 인덱스의 문서를 삭제하면 좋다.

```
DELETE .tasks/_doc/[task_id]
```

> **슬라이싱**
>

업데이트 성능을 최대로 끌어내 빠른 시간 안에 끝내고자 하는 경우(중단 배포같은 상황)에 유용한 방법으로 slices 매개변수를 지정하면 **검색과 업데이트를 지정한 개수로 쪼개 병렬적으로 수행**한다.

```
POST [인덱스 이름]/_update_by_query?slices=auto
```

`slices` 의 기본값은 1로, 작업을 병렬로 쪼개지 않는다는 뜻이다.

이 값을 auto로 지정하면 엘라스틱서치가 적절한 개수로 지정해서 작업을 병렬 수행한다.

보통은 지정한 인덱스의 주 샤드 수가 슬라이스의 수가 된다.

auto로 지정하지 않고 숫자로도 지정할 수 있는데 이 경우 슬라이스 수가 주 샤드 수를 넘는 경우 성능이 급감한다는 점을 유의하자. (추가로 메모리 부족이 발생할 수 있다)

또한 requests_per_second 옵션은 각 슬라이스에 쪼개져서 적용된다

ex) requests_per_second가 1000으로 지정하고 슬라이스 수가 5개라면 requests_per_seconds 200씩을 분배 받는다.

### 4.2.4 delete by query

지정한 검색 쿼리로 삭제할 대상을 지정한 뒤에 삭제를 수행하는 작업으로 update by query와 마찬가지로 관리적인 목적으로 많이 사용한다.

update by query와 다르게 주기적인 배치성 작업으로 수행하는 경우도 많다. (오래된 데이터를 삭제하는 경우)

```
POST [인덱스 이름]/_delete_by_query
{
	"query": {
			//...
	}
}
```

delete by query도 검색 조건에 맞는 문서를 찾아 스냅샷을 찍는다.

버전 충돌, 비동기 처리, tasks API를 통한 관리, 스로틀링 적용, 슬라이싱 적용도 update by query와 동일하다.