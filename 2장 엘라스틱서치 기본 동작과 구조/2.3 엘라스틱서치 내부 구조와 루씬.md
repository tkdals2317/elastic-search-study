## 2.3 엘라스틱서치 내부 구조와 루씬

루씬은 문서를 색인하고 검색하는 라이브러리로 엘라스틱서치는 아파치 루씬을 코어 라이브러리로 사용하고 있다.

이번 절에서는 이러한 루씬의 동작 특성을 알아보고 엘라스틱서치가 이 루씬을 어떻게 이용하는 지 알아본다.

### 2.3.1 루씬 flush

문서 색인 요청이 들어오면 루씬은 문서를 분석해서 역색인을 생성한다.

최초 생성 자체는 메모리 버퍼에 들어간다. 문서 색인, 업데이트, 삭제 등의 작업이 수행되면 루씬은 이러한 변경들을 메모리에 들고 있다가 주기적으로 디스크에 flush한다.

![2.4 루씬 flush](https://github.com/tkdals2317/elastic-search-study/assets/49682056/32df8e1c-bb57-49f5-b4db-0f1cc6ab0b03)

루씬은 색인한 정보를 파일로 저장하기 때문에 루씬에서 검색을 하려면 먼저 파일을 열어야 한다.

루씬은 파일을 연 시점에 색인이 완료된 문서만 검색할 수 있다. 이후 색인이 변경사항이 발생했고, 그 내용을 검색 결과에 반영하고 싶다면 파일을 새로 열어야 한다.

엘라스틱서치는 내부적으로 루씬의 DirectoryReader라는 클래스를 이용해 파일을 열고, 루씬의 색인에 접근할 수 있는 IndexReader 객체를 얻는다. 엘라스틱서치는 변경 내용을 검색에 반영하기 위해 루씬의 DirectoryReader.openIfChanged를 호출해 변경 사항이 적용된 새 IndexReader를 열어준 뒤 기존 IndexReader를 안전하게 닫는다. 이러한 작업을 **엘라스틱서치에서는 refresh**라고 한다.

이 단계까지 온 데이터가 검색 대상이 된다.

refresh 작업은 어느정도 **비용이 있는 작업이기 때문에** 엘라스틱서치 색인이 변경될 때마다 refresh를 수행하지 않고 **적절한 간격마다 주기적으로 실행**한다. 엘라스틱서치 refresh를 호출하면 필요에 따라 명시적으로 refresh 작업을 수행할 수도 있다.

### 2.3.2 루씬 commit

**루씬의 flush**는 **시스템의 페이지 캐시에 데이터를 넘겨주는 것까지만 보장할 뿐 디스크에 파일이 실제로 안전하게 기록되는 것까지 보장하지는 않는다.**

따라서 루씬의 fsync 시스템 콜을 통해 주기적으로 커널 시스템의 **페이지 캐시의 내용**과 **실제로 디스크에 기록된 내용**의 **싱크를 맞추는 작업을 수행**한다. 이를 **루씬의 commit**이라고 한다.

엘라스틱서치의 flush 작업은 내부적으로 이 루씬의 commit을 거친다.

**루씬의 flush와 엘라스틱서치의 flush는 다른 개념이기 때문에 혼동하지 말자**

엘라스틱서치의 flush는 엘라스틱서치의 refresh보다 훨씬 비용이 드는 작업이다. 그렇기 때문에 **refresh와 마찬가지로 적절한 주기로 수행된다.**

명시적으로 flush를 수행할수도 있다.

![2.5 루씬 commit](https://github.com/tkdals2317/elastic-search-study/assets/49682056/0a31a1c1-3eec-4c21-a814-7830130ec0dd)


### 2.3.3 세그먼트

앞의 작업을 거쳐 **디스크에 기록된 파일들이 모이면 세그먼트라는 단위**가 된다.

이 **세그먼트가 루씬의 검색 대상**이다. 세그먼트 자체는 **불변(immutable)인 데이터**로 구성돼 있다.

- 새로운 문서 저장 → 새 세그먼트가 생성
- 기존 문서를 삭제하는 경우 → 삭제 플래그만 표시해둔다.
- 기존 문서에 업데이트가 발생한 경우 → 삭제 플래그만 표시하고 새 세그먼트를 생성한다.

루씬의 검색은 모든 세그먼트를 대상으로 수행된다. 불변인 세그먼트를 무작정 늘려갈 수 없기에 **중간중간 적당히 세그먼트의 병합이 수행**된다.

세그먼트 **병합이 수행될 때 삭제 플래그가 표시된 데이터를 실제로 삭제하는 작업**도 수행한다.

![2.6 세그먼트 병합](https://github.com/tkdals2317/elastic-search-study/assets/49682056/fc6662ac-69e5-4da1-b2e8-a5b1f210a2ac)


세그먼트 병합은 비싼 작업이지만 일단 병합하면 **검색 성능 향상을 기대**할 수 있다.

forcemerge API로 명시적으로 세그먼트 병합을 수행할 수 있다.

⇒ 누락이 발생할 수 있으니 추가 데이터 색인이 없음이 보장될 때만 수행하자

### 2.3.4 루씬의 인덱스와 엘라스틱서치 인덱스

**여러 세그먼트가 모이면** 하나의 **루씬 인덱스**가 된다. 루씬은 이 인덱스 내에서만 검색이 가능하다.

**엘라스틱서치 샤드**는 이 **루씬 인덱스 하나를 래핑한 단위**다.

![2.7 루씬 인덱스와 엘라스틱서치 샤드](https://github.com/tkdals2317/elastic-search-study/assets/49682056/f31a5bd3-73eb-4cc2-b550-90a5cc8735d2)


**엘라스틱서치 샤드 여러개**가 모이면 **엘라스틱서치 인덱스**가 된다.

엘라스틱서치 레벨에서는 여러 샤드에 있는 문서를 모두 검색할 수 있다.

새 문서가 들어오면 해당 내용을 라우팅하여 여러 샤드에 분산시켜 저장, 색인한다.

이후 클라이언트가 엘라스틱서치에 검색 요청을 보내면 엘라스틱서치는 해당하는 각 샤드를 대상으로 검색을 한 뒤 그 결과를 모아 병합하여 최종 응답을 만든다.

⇒ 루씬 레벨에서는 불가능한 분산 검색을 엘라스틱서치 레벨에서는 가능하게 만듬

![2.8 엘라스틱서치 인덱스의 구조](https://github.com/tkdals2317/elastic-search-study/assets/49682056/cf479c56-268b-4b3e-b8d2-6368d625ff7a)

그림 2.2에서 살펴봤듯이 엘라스틱서치 인덱스를 구성하는 샤드는 여러 노드에 분산돼 있다.

**이러한 노드가 모여서 하나의 엘라스틱서치 클러스터가 된다.**

### 2.3.5 translog

변경사항을 모아서 commit할 시 장애 발생시 미처 commit되지 않은 **데이터가 유실될 우려**가 있어 **이 문제를 해결하기 위해 translog라는 이름의 작업 로그를 남긴다.**

translog는 **색인, 삭제 작업이 루씬 인덱스에 수행된 직후에 기록**된다.

translog 기록까지 끝난 이후에야 작업 요청이 성공으로 승인된다.

**엘라스틱서치에 장애가 발생한 경우**

**(1) 엘라스틱서치는 샤드 복구 단계에서 translog를 읽는다.**

**(2) translog 기록은 성공했지만 루씬의 commit에 포함되지 못했던 작업 내용이 있다면 샤드 복구 단계에서 복구된다.**

trnaslog가 너무 커지면 샤드 복구에 시간이 오래 걸리게 된다. 이를 방지하기 위해 translog의 크기를 적절히 유지해줄 필요가 있다.

앞에서 살펴봤던 엘라스틱서치 flush는 루씬 commit을 수행하고 새로운 translog를 만드는 작업이다.

이 엘라스틱서치 flush가 백그라운드에서 주기적으로 수행되며 translog의 크기를 적절한 수준으로 유지한다.

![2.9 translog](https://github.com/tkdals2317/elastic-search-study/assets/49682056/daebb508-f10a-4129-b3ce-3b1802d14586)

translog에는 디스크에 fsync된 데이터만 보존된다.

클라이언트가 색인, 삭제, 업데이트 등의 요청을 보냈을 때 엘라스틱서치는 translog를 성공적으로 fsync됐을 때에만 성공을 보고한다.